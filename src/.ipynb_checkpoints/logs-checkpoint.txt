Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.658274 train_inte_loss: 1.658274 train_speech_loss: 1.691658 train_face_loss: 1.949743 valid_loss: 1.651341 valid_inte_loss: 1.651341 valid_speech_loss: 1.716255 valid_face_loss: 1.951243 valid_acc: 0.394477
Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.664079 train_inte_loss: 1.664079 train_speech_loss: 1.687519 train_face_loss: 1.946603 valid_loss: 1.580457 valid_inte_loss: 1.580457 valid_speech_loss: 1.620618 valid_face_loss: 1.945523 valid_acc: 0.408648
Loaded pretrained weights for efficientnet-b4
Loaded pretrained weights for efficientnet-b4
Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.933656 valid_loss: 1.969087 valid_acc:0.150182
Epoch [1]/[100] train_loss: 3.455189 valid_loss: 2.341808 valid_acc:0.122638
Epoch [2]/[100] train_loss: 2.847213 valid_loss: 2.770787 valid_acc:0.121548
Epoch [3]/[100] train_loss: 3.663655 valid_loss: 3.273948 valid_acc:0.150363
Epoch [4]/[100] train_loss: 2.759599 valid_loss: 2.467166 valid_acc:0.207340
Epoch [5]/[100] train_loss: 3.089605 valid_loss: 2.205388 valid_acc:0.129724
Epoch [6]/[100] train_loss: 2.949807 valid_loss: 2.430108 valid_acc:0.148583
Epoch [7]/[100] train_loss: 3.022199 valid_loss: 2.234251 valid_acc:0.195531
Epoch [8]/[100] train_loss: 3.210823 valid_loss: 2.218605 valid_acc:0.151635
Epoch [9]/[100] train_loss: 2.733756 valid_loss: 2.846597 valid_acc:0.107703
Epoch [10]/[100] train_loss: 3.093233 valid_loss: 2.570094 valid_acc:0.108430
Loaded pretrained weights for efficientnet-b4
Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.932007 valid_loss: 1.967243 valid_acc:0.187936
Epoch [1]/[100] train_loss: 4.305975 valid_loss: 40.519786 valid_acc:0.147529
Epoch [2]/[100] train_loss: 3.626593 valid_loss: 5.894536 valid_acc:0.141642
Epoch [3]/[100] train_loss: 2.805047 valid_loss: 2.263963 valid_acc:0.113917
Epoch [4]/[100] train_loss: 3.767475 valid_loss: 2.175701 valid_acc:0.207158
Epoch [5]/[100] train_loss: 2.532604 valid_loss: 2.173516 valid_acc:0.149310
Epoch [6]/[100] train_loss: 3.329528 valid_loss: 2.819815 valid_acc:0.107703
Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.922670 valid_loss: 1.986380 valid_acc:0.163808
Epoch [1]/[100] train_loss: 1.903057 valid_loss: 1.829606 valid_acc:0.282885
Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.924623 valid_loss: 1.959066 valid_acc:0.144368
Epoch [1]/[100] train_loss: 1.920869 valid_loss: 3.069311 valid_acc:0.203961
Epoch [2]/[100] train_loss: 1.926424 valid_loss: 6.116387 valid_acc:0.150036
Epoch [3]/[100] train_loss: 4.507344 valid_loss: 2.338135 valid_acc:0.107703
Epoch [4]/[100] train_loss: 2.429481 valid_loss: 2.287800 valid_acc:0.207158
Epoch [5]/[100] train_loss: 2.277913 valid_loss: 2.160547 valid_acc:0.107703
Epoch [6]/[100] train_loss: 2.292902 valid_loss: 2.206400 valid_acc:0.207158
Epoch [7]/[100] train_loss: 2.296799 valid_loss: 2.293875 valid_acc:0.149310
Epoch [8]/[100] train_loss: 2.229739 valid_loss: 2.061545 valid_acc:0.207158
Epoch [9]/[100] train_loss: 2.280034 valid_loss: 2.179302 valid_acc:0.154360
Epoch [10]/[100] train_loss: 2.239273 valid_loss: 1.942107 valid_acc:0.207158
Epoch [11]/[100] train_loss: 2.245614 valid_loss: 2.066161 valid_acc:0.107703
Epoch [12]/[100] train_loss: 2.265081 valid_loss: 1.942762 valid_acc:0.154360
Epoch [13]/[100] train_loss: 2.225317 valid_loss: 2.078845 valid_acc:0.207158
Epoch [14]/[100] train_loss: 2.278467 valid_loss: 2.039294 valid_acc:0.141642
Epoch [15]/[100] train_loss: 2.217917 valid_loss: 2.197654 valid_acc:0.207158
Epoch [16]/[100] train_loss: 2.279244 valid_loss: 2.531279 valid_acc:0.107703
Epoch [17]/[100] train_loss: 2.191144 valid_loss: 2.170991 valid_acc:0.113917
Epoch [18]/[100] train_loss: 2.224314 valid_loss: 1.998255 valid_acc:0.149310
Epoch [19]/[100] train_loss: 2.204345 valid_loss: 2.037184 valid_acc:0.207158
Epoch [20]/[100] train_loss: 2.244301 valid_loss: 1.987142 valid_acc:0.207158
Epoch [21]/[100] train_loss: 2.190945 valid_loss: 2.181325 valid_acc:0.149310
Epoch [22]/[100] train_loss: 2.256569 valid_loss: 2.209518 valid_acc:0.141642
Epoch [23]/[100] train_loss: 2.236991 valid_loss: 2.066860 valid_acc:0.207158
Epoch [24]/[100] train_loss: 2.203807 valid_loss: 2.016645 valid_acc:0.141642
Epoch [25]/[100] train_loss: 2.205959 valid_loss: 2.036691 valid_acc:0.207158
Epoch [26]/[100] train_loss: 2.228216 valid_loss: 2.016984 valid_acc:0.141642
Epoch [27]/[100] train_loss: 2.179173 valid_loss: 2.039317 valid_acc:0.113917
Epoch [28]/[100] train_loss: 2.197986 valid_loss: 2.222582 valid_acc:0.207158
Epoch [29]/[100] train_loss: 2.213947 valid_loss: 2.139572 valid_acc:0.207158
Epoch [30]/[100] train_loss: 2.204353 valid_loss: 1.965144 valid_acc:0.154360
Epoch [31]/[100] train_loss: 2.163707 valid_loss: 1.944816 valid_acc:0.207158
Epoch [32]/[100] train_loss: 2.197022 valid_loss: 2.092488 valid_acc:0.141642
Epoch [33]/[100] train_loss: 2.173603 valid_loss: 2.060669 valid_acc:0.207158
Epoch [34]/[100] train_loss: 2.156763 valid_loss: 2.204909 valid_acc:0.141642
Epoch [35]/[100] train_loss: 2.157459 valid_loss: 2.014778 valid_acc:0.207158
Epoch [36]/[100] train_loss: 2.152401 valid_loss: 2.194530 valid_acc:0.125908
Epoch [37]/[100] train_loss: 2.163369 valid_loss: 2.118938 valid_acc:0.207158
Epoch [38]/[100] train_loss: 2.136868 valid_loss: 1.975310 valid_acc:0.141642
Epoch [39]/[100] train_loss: 2.174970 valid_loss: 2.050468 valid_acc:0.149310
Epoch [40]/[100] train_loss: 2.136387 valid_loss: 2.126181 valid_acc:0.107703
Epoch [41]/[100] train_loss: 2.135977 valid_loss: 2.059650 valid_acc:0.149310
Epoch [42]/[100] train_loss: 2.146363 valid_loss: 2.201312 valid_acc:0.149310
Epoch [43]/[100] train_loss: 2.154627 valid_loss: 2.058675 valid_acc:0.154360
Epoch [44]/[100] train_loss: 2.119423 valid_loss: 2.164349 valid_acc:0.149310
Epoch [45]/[100] train_loss: 2.124644 valid_loss: 1.968308 valid_acc:0.154360
Epoch [46]/[100] train_loss: 2.125826 valid_loss: 2.075176 valid_acc:0.207158
Epoch [47]/[100] train_loss: 2.101604 valid_loss: 1.993347 valid_acc:0.154360
Epoch [48]/[100] train_loss: 2.104667 valid_loss: 2.079040 valid_acc:0.113917
Epoch [49]/[100] train_loss: 2.101966 valid_loss: 2.050624 valid_acc:0.141642
Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.923967 valid_loss: 1.951804 valid_acc:0.165661
Epoch [1]/[100] train_loss: 1.907850 valid_loss: 1.914427 valid_acc:0.230741
Epoch [2]/[100] train_loss: 1.903199 valid_loss: 1.926107 valid_acc:0.291461
Epoch [3]/[100] train_loss: 1.895268 valid_loss: 1.993445 valid_acc:0.262028
Epoch [4]/[100] train_loss: 1.886637 valid_loss: 1.872310 valid_acc:0.243859
Epoch [5]/[100] train_loss: 1.880510 valid_loss: 1.828618 valid_acc:0.288699
Epoch [6]/[100] train_loss: 1.878936 valid_loss: 1.826450 valid_acc:0.237609
Epoch [7]/[100] train_loss: 1.878680 valid_loss: 1.897330 valid_acc:0.247166
Epoch [8]/[100] train_loss: 1.874539 valid_loss: 1.827964 valid_acc:0.286083
Epoch [9]/[100] train_loss: 1.875144 valid_loss: 1.962290 valid_acc:0.243714
Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.919015 valid_loss: 1.908552 valid_acc:0.233830
Epoch [1]/[100] train_loss: 1.904788 valid_loss: 1.888934 valid_acc:0.235065
Epoch [2]/[100] train_loss: 1.899858 valid_loss: 1.922121 valid_acc:0.226453
Epoch [3]/[100] train_loss: 1.893371 valid_loss: 1.878296 valid_acc:0.223910
Epoch [4]/[100] train_loss: 1.880208 valid_loss: 1.804178 valid_acc:0.276962
Epoch [5]/[100] train_loss: 1.873451 valid_loss: 1.787657 valid_acc:0.290516
Epoch [6]/[100] train_loss: 1.869680 valid_loss: 1.795859 valid_acc:0.305959
Epoch [7]/[100] train_loss: 1.865180 valid_loss: 1.783252 valid_acc:0.307631
Epoch [8]/[100] train_loss: 1.862210 valid_loss: 1.763499 valid_acc:0.317260
Epoch [9]/[100] train_loss: 1.863050 valid_loss: 1.843748 valid_acc:0.253525
Epoch [10]/[100] train_loss: 1.856212 valid_loss: 1.789528 valid_acc:0.309593
Epoch [11]/[100] train_loss: 1.852641 valid_loss: 1.733215 valid_acc:0.324128
Epoch [12]/[100] train_loss: 1.849011 valid_loss: 1.731400 valid_acc:0.327798
Epoch [13]/[100] train_loss: 1.851483 valid_loss: 1.717097 valid_acc:0.340843
Epoch [14]/[100] train_loss: 1.846384 valid_loss: 1.715566 valid_acc:0.340262
Epoch [15]/[100] train_loss: 1.845458 valid_loss: 1.694880 valid_acc:0.344876
Epoch [16]/[100] train_loss: 1.841025 valid_loss: 1.713877 valid_acc:0.345203
Epoch [17]/[100] train_loss: 1.837680 valid_loss: 1.721417 valid_acc:0.320894
Epoch [18]/[100] train_loss: 1.836216 valid_loss: 1.672338 valid_acc:0.368750
Epoch [19]/[100] train_loss: 1.835124 valid_loss: 1.757828 valid_acc:0.294513
Epoch [20]/[100] train_loss: 1.833216 valid_loss: 1.684445 valid_acc:0.344477
Epoch [21]/[100] train_loss: 1.834681 valid_loss: 1.706295 valid_acc:0.340116
Epoch [22]/[100] train_loss: 1.830517 valid_loss: 1.673757 valid_acc:0.364898
Epoch [23]/[100] train_loss: 1.830225 valid_loss: 1.698212 valid_acc:0.354433
Epoch [24]/[100] train_loss: 1.824979 valid_loss: 1.670040 valid_acc:0.360392
Epoch [25]/[100] train_loss: 1.825756 valid_loss: 1.671294 valid_acc:0.364644
Epoch [26]/[100] train_loss: 1.828291 valid_loss: 1.768024 valid_acc:0.285465
Epoch [27]/[100] train_loss: 1.822148 valid_loss: 1.743669 valid_acc:0.303089
Epoch [28]/[100] train_loss: 1.818502 valid_loss: 1.648551 valid_acc:0.375690
Epoch [29]/[100] train_loss: 1.818109 valid_loss: 1.665400 valid_acc:0.361555
Epoch [30]/[100] train_loss: 1.813827 valid_loss: 1.734498 valid_acc:0.337718
Epoch [31]/[100] train_loss: 1.812651 valid_loss: 1.646047 valid_acc:0.361882
Epoch [32]/[100] train_loss: 1.813070 valid_loss: 1.666095 valid_acc:0.373547
Epoch [33]/[100] train_loss: 1.808640 valid_loss: 1.657174 valid_acc:0.374746
Epoch [34]/[100] train_loss: 1.810553 valid_loss: 1.623660 valid_acc:0.391315
Epoch [35]/[100] train_loss: 1.810016 valid_loss: 1.644873 valid_acc:0.373219
Epoch [36]/[100] train_loss: 1.801807 valid_loss: 1.719577 valid_acc:0.323801
Epoch [37]/[100] train_loss: 1.802141 valid_loss: 1.639430 valid_acc:0.382776
Epoch [38]/[100] train_loss: 1.804253 valid_loss: 1.623163 valid_acc:0.390262
Epoch [39]/[100] train_loss: 1.801148 valid_loss: 1.620181 valid_acc:0.388735
Epoch [40]/[100] train_loss: 1.798377 valid_loss: 1.623247 valid_acc:0.385320
Epoch [41]/[100] train_loss: 1.804351 valid_loss: 1.627348 valid_acc:0.388118
Epoch [42]/[100] train_loss: 1.798394 valid_loss: 1.668061 valid_acc:0.355196
Epoch [43]/[100] train_loss: 1.799152 valid_loss: 1.618815 valid_acc:0.389317
Epoch [44]/[100] train_loss: 1.791600 valid_loss: 1.616120 valid_acc:0.396185
Epoch [45]/[100] train_loss: 1.789567 valid_loss: 1.604852 valid_acc:0.396948
Epoch [46]/[100] train_loss: 1.791956 valid_loss: 1.601951 valid_acc:0.400545
Epoch [47]/[100] train_loss: 1.792429 valid_loss: 1.620111 valid_acc:0.387318
Epoch [48]/[100] train_loss: 1.781323 valid_loss: 1.624149 valid_acc:0.398728
Epoch [49]/[100] train_loss: 1.780281 valid_loss: 1.607822 valid_acc:0.396439
Epoch [50]/[100] train_loss: 1.783880 valid_loss: 1.604345 valid_acc:0.387863
Epoch [51]/[100] train_loss: 1.777770 valid_loss: 1.608031 valid_acc:0.400000
Epoch [52]/[100] train_loss: 1.776708 valid_loss: 1.598198 valid_acc:0.396257
Epoch [53]/[100] train_loss: 1.776401 valid_loss: 1.607360 valid_acc:0.388299
Epoch [54]/[100] train_loss: 1.773743 valid_loss: 1.601070 valid_acc:0.390916
Epoch [55]/[100] train_loss: 1.772536 valid_loss: 1.596655 valid_acc:0.399673
Epoch [56]/[100] train_loss: 1.773934 valid_loss: 1.617882 valid_acc:0.379215
Epoch [57]/[100] train_loss: 1.772460 valid_loss: 1.580417 valid_acc:0.411991
Epoch [58]/[100] train_loss: 1.770752 valid_loss: 1.574875 valid_acc:0.416061
Epoch [59]/[100] train_loss: 1.768268 valid_loss: 1.617360 valid_acc:0.375908
Epoch [60]/[100] train_loss: 1.765098 valid_loss: 1.625240 valid_acc:0.372856
Epoch [61]/[100] train_loss: 1.772628 valid_loss: 1.592695 valid_acc:0.400436
Epoch [62]/[100] train_loss: 1.761595 valid_loss: 1.574775 valid_acc:0.403597
Epoch [63]/[100] train_loss: 1.760244 valid_loss: 1.577871 valid_acc:0.409702
Epoch [64]/[100] train_loss: 1.759378 valid_loss: 1.575442 valid_acc:0.413663
Epoch [65]/[100] train_loss: 1.752290 valid_loss: 1.589726 valid_acc:0.400036
Epoch [66]/[100] train_loss: 1.747170 valid_loss: 1.567710 valid_acc:0.410938
Epoch [67]/[100] train_loss: 1.754687 valid_loss: 1.568974 valid_acc:0.401708
Epoch [68]/[100] train_loss: 1.752183 valid_loss: 1.579166 valid_acc:0.397347
Epoch [69]/[100] train_loss: 1.751240 valid_loss: 1.579756 valid_acc:0.394259
Epoch [70]/[100] train_loss: 1.745561 valid_loss: 1.569432 valid_acc:0.408067
Epoch [71]/[100] train_loss: 1.745892 valid_loss: 1.563590 valid_acc:0.409121
Epoch [72]/[100] train_loss: 1.749159 valid_loss: 1.557500 valid_acc:0.424019
Epoch [73]/[100] train_loss: 1.740509 valid_loss: 1.565983 valid_acc:0.409884
Epoch [74]/[100] train_loss: 1.742531 valid_loss: 1.573300 valid_acc:0.399419
Epoch [75]/[100] train_loss: 1.742936 valid_loss: 1.558073 valid_acc:0.414826
Epoch [76]/[100] train_loss: 1.733115 valid_loss: 1.574566 valid_acc:0.408212
Epoch [77]/[100] train_loss: 1.735115 valid_loss: 1.560851 valid_acc:0.408648
Epoch [78]/[100] train_loss: 1.739392 valid_loss: 1.562357 valid_acc:0.414608
Epoch [79]/[100] train_loss: 1.749644 valid_loss: 1.553588 valid_acc:0.420930
Epoch [80]/[100] train_loss: 1.737097 valid_loss: 1.561742 valid_acc:0.416606
Epoch [81]/[100] train_loss: 1.734599 valid_loss: 1.558014 valid_acc:0.419695
Epoch [82]/[100] train_loss: 1.731430 valid_loss: 1.553987 valid_acc:0.415189
Epoch [83]/[100] train_loss: 1.729980 valid_loss: 1.557650 valid_acc:0.417515
Epoch [84]/[100] train_loss: 1.728975 valid_loss: 1.556525 valid_acc:0.412827
Epoch [85]/[100] train_loss: 1.730236 valid_loss: 1.561108 valid_acc:0.414462
Epoch [86]/[100] train_loss: 1.735230 valid_loss: 1.557876 valid_acc:0.416097
Epoch [87]/[100] train_loss: 1.726539 valid_loss: 1.558547 valid_acc:0.413009
Epoch [88]/[100] train_loss: 1.728493 valid_loss: 1.557777 valid_acc:0.415189
Epoch [89]/[100] train_loss: 1.719981 valid_loss: 1.552774 valid_acc:0.417006
Epoch [90]/[100] train_loss: 1.731107 valid_loss: 1.554750 valid_acc:0.415916
Epoch [91]/[100] train_loss: 1.730822 valid_loss: 1.556574 valid_acc:0.416788
Epoch [92]/[100] train_loss: 1.723219 valid_loss: 1.552956 valid_acc:0.416097
Epoch [93]/[100] train_loss: 1.724801 valid_loss: 1.554197 valid_acc:0.413917
Epoch [94]/[100] train_loss: 1.716906 valid_loss: 1.552813 valid_acc:0.413917
Epoch [95]/[100] train_loss: 1.725100 valid_loss: 1.554664 valid_acc:0.414462
Epoch [96]/[100] train_loss: 1.731966 valid_loss: 1.558495 valid_acc:0.412246
Epoch [97]/[100] train_loss: 1.730765 valid_loss: 1.557219 valid_acc:0.411737
Epoch [98]/[100] train_loss: 1.721302 valid_loss: 1.555965 valid_acc:0.412282
Epoch [99]/[100] train_loss: 1.720340 valid_loss: 1.555750 valid_acc:0.413009
Loaded pretrained weights for efficientnet-b4
Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.922670 valid_loss: 1.986380 valid_acc:0.163808
Epoch [1]/[100] train_loss: 1.903057 valid_loss: 1.829606 valid_acc:0.282885
Epoch [2]/[100] train_loss: 1.895775 valid_loss: 1.857869 valid_acc:0.278779
Epoch [3]/[100] train_loss: 1.888396 valid_loss: 1.835889 valid_acc:0.296693
Epoch [4]/[100] train_loss: 1.876603 valid_loss: 1.766797 valid_acc:0.311228
Epoch [5]/[100] train_loss: 1.873733 valid_loss: 1.880921 valid_acc:0.271657
Epoch [6]/[100] train_loss: 1.867870 valid_loss: 1.770733 valid_acc:0.311228
Epoch [7]/[100] train_loss: 1.867625 valid_loss: 1.770432 valid_acc:0.311592
Epoch [8]/[100] train_loss: 1.862394 valid_loss: 1.815410 valid_acc:0.269295
Epoch [9]/[100] train_loss: 1.866779 valid_loss: 1.776362 valid_acc:0.304506
Epoch [10]/[100] train_loss: 1.851076 valid_loss: 1.758834 valid_acc:0.307376
Epoch [11]/[100] train_loss: 1.850454 valid_loss: 1.734680 valid_acc:0.330669
Epoch [12]/[100] train_loss: 2.866526 valid_loss: 2.014389 valid_acc:0.125908
Epoch [13]/[100] train_loss: 2.055285 valid_loss: 2.077693 valid_acc:0.125908
Epoch [14]/[100] train_loss: 2.028522 valid_loss: 1.967935 valid_acc:0.154360
Epoch [15]/[100] train_loss: 2.026139 valid_loss: 2.086464 valid_acc:0.207158
Epoch [16]/[100] train_loss: 2.026835 valid_loss: 2.032729 valid_acc:0.154360
Epoch [17]/[100] train_loss: 2.022804 valid_loss: 1.987590 valid_acc:0.154360
Loaded pretrained weights for efficientnet-b4
Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 1.924808 valid_loss: 1.915385 valid_acc:0.218205
Epoch [1]/[100] train_loss: 1.891025 valid_loss: 1.955622 valid_acc:0.272820
Epoch [2]/[100] train_loss: 1.882208 valid_loss: 1.910400 valid_acc:0.248401
Epoch [3]/[100] train_loss: 1.874078 valid_loss: 1.886304 valid_acc:0.244331
Epoch [4]/[100] train_loss: 1.868593 valid_loss: 1.755307 valid_acc:0.307049
Epoch [5]/[100] train_loss: 1.863807 valid_loss: 1.819552 valid_acc:0.284811
Epoch [6]/[100] train_loss: 1.860305 valid_loss: 1.749962 valid_acc:0.330124
Epoch [7]/[100] train_loss: 1.857273 valid_loss: 1.890098 valid_acc:0.249709
Epoch [8]/[100] train_loss: 1.854077 valid_loss: 1.766989 valid_acc:0.303852
Epoch [9]/[100] train_loss: 1.853263 valid_loss: 1.779360 valid_acc:0.298474
Epoch [10]/[100] train_loss: 1.846486 valid_loss: 1.773792 valid_acc:0.310174
Epoch [11]/[100] train_loss: 1.846171 valid_loss: 1.763456 valid_acc:0.301235
Epoch [12]/[100] train_loss: 1.840315 valid_loss: 1.752279 valid_acc:0.319804
Epoch [13]/[100] train_loss: 1.841643 valid_loss: 1.749284 valid_acc:0.310719
Epoch [14]/[100] train_loss: 1.840962 valid_loss: 1.733011 valid_acc:0.313263
Epoch [15]/[100] train_loss: 1.837050 valid_loss: 1.802587 valid_acc:0.291424
Epoch [16]/[100] train_loss: 1.835158 valid_loss: 1.696735 valid_acc:0.351744
Epoch [17]/[100] train_loss: 1.834010 valid_loss: 1.704037 valid_acc:0.337391
Epoch [18]/[100] train_loss: 1.831087 valid_loss: 1.692202 valid_acc:0.349927
Epoch [19]/[100] train_loss: 1.829298 valid_loss: 1.752500 valid_acc:0.311192
Epoch [20]/[100] train_loss: 1.829280 valid_loss: 1.719673 valid_acc:0.332304
Epoch [21]/[100] train_loss: 1.829949 valid_loss: 1.663987 valid_acc:0.364462
Epoch [22]/[100] train_loss: 1.822787 valid_loss: 1.667295 valid_acc:0.361955
Epoch [23]/[100] train_loss: 1.820579 valid_loss: 1.693389 valid_acc:0.349164
Epoch [24]/[100] train_loss: 1.818900 valid_loss: 1.680663 valid_acc:0.359411
Epoch [25]/[100] train_loss: 1.818075 valid_loss: 1.692693 valid_acc:0.349528
Epoch [26]/[100] train_loss: 1.819985 valid_loss: 1.669330 valid_acc:0.358830
Epoch [27]/[100] train_loss: 1.815096 valid_loss: 1.637183 valid_acc:0.368278
Epoch [28]/[100] train_loss: 1.810394 valid_loss: 1.644540 valid_acc:0.375872
Epoch [29]/[100] train_loss: 1.809247 valid_loss: 1.685914 valid_acc:0.344150
Epoch [30]/[100] train_loss: 1.807810 valid_loss: 1.651489 valid_acc:0.380051
Epoch [31]/[100] train_loss: 1.806552 valid_loss: 1.657974 valid_acc:0.374382
Epoch [32]/[100] train_loss: 1.801246 valid_loss: 1.692141 valid_acc:0.345094
Epoch [33]/[100] train_loss: 1.802325 valid_loss: 1.627668 valid_acc:0.379324
Epoch [34]/[100] train_loss: 1.802477 valid_loss: 1.650341 valid_acc:0.380378
Epoch [35]/[100] train_loss: 1.802280 valid_loss: 1.628674 valid_acc:0.383212
Epoch [36]/[100] train_loss: 1.792189 valid_loss: 1.621665 valid_acc:0.386810
Epoch [37]/[100] train_loss: 1.794710 valid_loss: 1.598406 valid_acc:0.393169
Epoch [38]/[100] train_loss: 1.797011 valid_loss: 1.627456 valid_acc:0.392369
Epoch [39]/[100] train_loss: 1.790637 valid_loss: 1.615624 valid_acc:0.396911
Epoch [40]/[100] train_loss: 1.788228 valid_loss: 1.635661 valid_acc:0.380778
Epoch [41]/[100] train_loss: 1.794161 valid_loss: 1.628696 valid_acc:0.378634
Epoch [42]/[100] train_loss: 1.787155 valid_loss: 1.597583 valid_acc:0.400545
Epoch [43]/[100] train_loss: 1.787028 valid_loss: 1.578875 valid_acc:0.404070
Epoch [44]/[100] train_loss: 1.781948 valid_loss: 1.611755 valid_acc:0.394876
Epoch [45]/[100] train_loss: 1.779018 valid_loss: 1.591323 valid_acc:0.409048
Epoch [46]/[100] train_loss: 1.783270 valid_loss: 1.568909 valid_acc:0.412209
Epoch [47]/[100] train_loss: 1.779251 valid_loss: 1.597673 valid_acc:0.393387
Epoch [48]/[100] train_loss: 1.772750 valid_loss: 1.590320 valid_acc:0.400145
Epoch [49]/[100] train_loss: 1.769754 valid_loss: 1.604989 valid_acc:0.400908
Epoch [50]/[100] train_loss: 1.771613 valid_loss: 1.575112 valid_acc:0.411846
Epoch [51]/[100] train_loss: 1.768218 valid_loss: 1.589028 valid_acc:0.417188
Epoch [52]/[100] train_loss: 1.763269 valid_loss: 1.574262 valid_acc:0.419259
